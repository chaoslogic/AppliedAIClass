{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 14: Grid search for designing a deep feedforward network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f82QjFF3Gm1A"
      },
      "source": [
        "# **Session 14: Grid search for designing a deep feedforward network**\n",
        "\n",
        "\n",
        "## PY599 (Fall 2018): Applied Artificial Intelligence\n",
        "## NC State University\n",
        "###Dr. Behnam Kia\n",
        "### https://appliedai.wordpress.ncsu.edu/\n",
        "\n",
        "\n",
        "**Disclaimer**: Please note that these codes are simplified version of the algorithms, and they may not give the best, or expected performance that you could possibly get from these algorithms. The aim of this notebook is to help you understand the basics and the essence of these algorithms, and experiment with them. These basic codes are not deployment-ready or free-of-errors for real-world applications. To learn more about these algorithms please refer to text books that specifically study these algorithms, or contact me. - Behnam Kia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "516rzvjHEPQD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a802c9e5-cb9d-46c8-d5a4-85bde551bbe2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def create_model(optimizer='sgd', activation = 'relu', hidden_layers=1):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Dense(10, input_dim=784, activation='relu'))  # Add the first hidden layer. Let's assume we have 16 inputs, that's why input_dim=16\n",
        "\n",
        "  for i in range(hidden_layers-1):                          # here we are adding the addiitonal hidden layers\n",
        "      model.add(Dense(10, activation=activation))            # note that the number of neurons in the hidden layer (here 10) could be a hyperparameter too.\n",
        "\n",
        "\n",
        "  model.add(Dense(10, activation='softmax'))                    #this is our output layer. \n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=\n",
        "  ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H09xN0eDcjy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0800f296-fb4e-49ff-d6d8-d8750690f0ab"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "num_of_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_of_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_of_pixels).astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "num_classes = Y_test.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = [10]# [10,20, 40, 60, 80, 100]\n",
        "epochs = [3] # [10, 50, 100]\n",
        "optimizer = ['SGD', 'RMSprop']    #  optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "my_classifier = KerasClassifier(build_fn=create_model, verbose=0)   # use KerasRegressor for regression models and problems\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer=optimizer)\n",
        "\n",
        "grid = GridSearchCV(estimator=my_classifier, param_grid=param_grid) \n",
        "\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "\n",
        "grid_result.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 10, 'epochs': 3, 'optimizer': 'RMSprop'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6vf8IKPkuCJ"
      },
      "source": [
        "\n",
        "\n",
        "also take a look at https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ8PmD4hPrRF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9b5446b-805e-4df9-aec7-6cdfdcaf04f1"
      },
      "source": [
        "import sklearn\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The scikit-learn version is 0.19.2.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}