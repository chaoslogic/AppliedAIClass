{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Document Classification using Naive Bayes Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JUWkOJJ8S59"
      },
      "source": [
        "# **Session 7: Probability and Statistics for AI & Machine Learning II**\n",
        "## Document Classification using Naive Bayes Classifier.\n",
        "\n",
        "## PY599 (Fall 2018): Applied Artificial Intelligence\n",
        "## NC State University\n",
        "###Dr. Behnam Kia\n",
        "### https://appliedai.wordpress.ncsu.edu/\n",
        "\n",
        "\n",
        "**Disclaimer**: Please note that these codes are simplified version of the algorithms, and they may not give the best, or expected performance that you could possibly get from these algorithms. The aim of this notebook is to help you understand the basics and the essence of these algorithms, and experiment with them. These basic codes are not deployment-ready or free-of-errors for real-world applications. To learn more about these algorithms please refer to text books that specifically study these algorithms, or contact me. - Behnam Kia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq1U3LBU7hQ-"
      },
      "source": [
        "# Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2InEE1wy7B6U"
      },
      "source": [
        "Method 1: You can download dataset from Keras. In this dataset the words are replaced by a unique number. According to Keras' website, \"Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
        "\n",
        "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2aenG6M6JZA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3585a90b-018e-40e0-f4ba-f1e342436083"
      },
      "source": [
        "\n",
        "from keras.datasets import imdb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
        "                                                      num_words=None,\n",
        "                                                      skip_top=0,\n",
        "                                                      maxlen=None,\n",
        "                                                      seed=113,\n",
        "                                                      start_char=1,\n",
        "                                                      oov_char=2,\n",
        "                                                      index_from=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0gCnTMK6ciV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d564782-3a77-4ca1-968b-78feadfe954a"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lohT1Yla6ehU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "22af3a0c-ded8-467a-aede-a4a123006d2b"
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2fuzlae7ooQ"
      },
      "source": [
        "Method 2: You can download the original dataset with readible reviews. Please go to: \n",
        "http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "and download \"Large Movie Review Dataset v1.0.\"\n",
        "\n",
        "There are many different methods to upload dataset to colab. \n",
        "One method is to download the dataset to your local computer, then upload it to colab and then unzip it. Please see the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebsg_pa96hhN"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "!tar xzvf aclImdb_v1.tar.gz >/dev/null\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gauB2ORDaNGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "f7169cf2-1011-4a0a-843d-73b02f64ae58"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
        "                                                      num_words=10,\n",
        "                                                      skip_top=0,\n",
        "                                                      maxlen=None,\n",
        "                                                      seed=113,\n",
        "                                                      start_char=1,\n",
        "                                                      oov_char=2,\n",
        "                                                      index_from=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-64c7c7e8df2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m (x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                       \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                       \u001b[0mskip_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                       \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                       \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m113\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'imdb' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxZKMPMUaXCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "0d5e8fa0-121b-4916-ee1a-8bd5e9041eee"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e20a593f9355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    }
  ]
}